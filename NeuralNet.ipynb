{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math, random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wermarter/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/wermarter/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/wermarter/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 395 entries, 0 to 394\n",
      "Data columns (total 8 columns):\n",
      "sex           395 non-null int64\n",
      "age           395 non-null int64\n",
      "famsize       395 non-null int64\n",
      "traveltime    395 non-null int64\n",
      "studytime     395 non-null int64\n",
      "activities    395 non-null int64\n",
      "goout         395 non-null int64\n",
      "famrel        395 non-null int64\n",
      "dtypes: int64(8)\n",
      "memory usage: 24.8 KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>famsize</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>activities</th>\n",
       "      <th>goout</th>\n",
       "      <th>famrel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.473418</td>\n",
       "      <td>16.696203</td>\n",
       "      <td>0.711392</td>\n",
       "      <td>1.448101</td>\n",
       "      <td>2.035443</td>\n",
       "      <td>0.508861</td>\n",
       "      <td>3.108861</td>\n",
       "      <td>3.944304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499926</td>\n",
       "      <td>1.276043</td>\n",
       "      <td>0.453690</td>\n",
       "      <td>0.697505</td>\n",
       "      <td>0.839240</td>\n",
       "      <td>0.500555</td>\n",
       "      <td>1.113278</td>\n",
       "      <td>0.896659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sex         age     famsize  traveltime   studytime  activities  \\\n",
       "count  395.000000  395.000000  395.000000  395.000000  395.000000  395.000000   \n",
       "mean     0.473418   16.696203    0.711392    1.448101    2.035443    0.508861   \n",
       "std      0.499926    1.276043    0.453690    0.697505    0.839240    0.500555   \n",
       "min      0.000000   15.000000    0.000000    1.000000    1.000000    0.000000   \n",
       "25%      0.000000   16.000000    0.000000    1.000000    1.000000    0.000000   \n",
       "50%      0.000000   17.000000    1.000000    1.000000    2.000000    1.000000   \n",
       "75%      1.000000   18.000000    1.000000    2.000000    2.000000    1.000000   \n",
       "max      1.000000   22.000000    1.000000    4.000000    4.000000    1.000000   \n",
       "\n",
       "            goout      famrel  \n",
       "count  395.000000  395.000000  \n",
       "mean     3.108861    3.944304  \n",
       "std      1.113278    0.896659  \n",
       "min      1.000000    1.000000  \n",
       "25%      2.000000    4.000000  \n",
       "50%      3.000000    4.000000  \n",
       "75%      4.000000    5.000000  \n",
       "max      5.000000    5.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('student-mat.csv')\n",
    "train_y = train[['romantic']]\n",
    "train = train[['sex', 'age', 'famsize', 'traveltime', 'studytime', 'activities', 'goout', 'famrel']]\n",
    "train_y['romantic'][train_y['romantic']=='no'] = 0\n",
    "train_y['romantic'][train_y['romantic']=='yes'] = 1\n",
    "train['sex'][train['sex']=='F'] = 0\n",
    "train['sex'][train['sex']=='M'] = 1\n",
    "train['famsize'][train['famsize']=='LE3'] = 0\n",
    "train['famsize'][train['famsize']=='GT3'] = 1\n",
    "train['activities'][train['activities']=='no'] = 0\n",
    "train['activities'][train['activities']=='yes'] = 1\n",
    "train = train.apply(pd.to_numeric)\n",
    "print(train.info())\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_dev_test(X, Y, dist):\n",
    "    s, m = sum(dist), len(X)\n",
    "    a, b, c = (np.array(dist) / s)\n",
    "    train_x, tmp_x, train_y, tmp_y = split(X, Y, test_size=(b+c)/a)\n",
    "    dev_x, test_x, dev_y, test_y = split(tmp_x, tmp_y, test_size=c/(b+c))\n",
    "    return train_x, dev_x, test_x, train_y, dev_y, test_y\n",
    "\n",
    "train_y = train_y.apply(pd.to_numeric).values\n",
    "train_x, dev_x, test_x, train_y, dev_y, test_y =train_dev_test(train.values, train_y, [7, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NeuralNetworkClassifier:\n",
    "    # Layers start from 0 (input data)\n",
    "    # Delta, Theta, Error is list() of numpy.array()\n",
    "    # \n",
    "    #\n",
    "    def __init__(self, hidden_layers=np.array([2]), learning_rate=0.005, reg_lambda=1, interval=300, epsilon=0.0001):\n",
    "        np.random.seed(37) # For consistency\n",
    "        self.L = len(hidden_layers)+2 # Number of layers\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.learning_rate = learning_rate\n",
    "        self.reg_lambda = reg_lambda # Lambda for Regularization\n",
    "        self.interval = interval # Interval for showing error rate (the norm function)\n",
    "        self.count = 0 # Supporting the intervals\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "\n",
    "    def score(self, X, Y, theta=None):\n",
    "        # Accuracy Scoring\n",
    "        res = 0\n",
    "        for x, y in zip(X, Y):\n",
    "            if self.predict(x, theta) == y:\n",
    "                res += 1\n",
    "        return res/len(X)\n",
    "            \n",
    "    def predict_proba(self, X, theta=None):\n",
    "        if theta == None:\n",
    "            theta = self.trained\n",
    "        return float(self.FeedForward(X, theta)[0][-1][0])\n",
    "    \n",
    "    def predict(self, X, theta=None):\n",
    "        res = self.predict_proba(X, theta)\n",
    "        return 1 if res > 0.5 else 0\n",
    "    \n",
    "    def fit(self, X, y): # Main\n",
    "        m, n = X.shape\n",
    "        layers = np.insert(np.insert(self.hidden_layers, 0, n), self.L-1, 1) # Numbers of nodes\n",
    "        print(layers)\n",
    "        theta = list() # Weights of each Layer\n",
    "        for l in range(self.L-1):\n",
    "            theta.append(np.random.random((layers[l+1], layers[l]))) # Exclude Bias\n",
    "        self.trained = self.GradientDescent(X, y, m, theta)\n",
    "        return \"We did it, dude!\"\n",
    "    \n",
    "    def Loss(self, X, Y, theta=None):\n",
    "        # Logistic Loss Function\n",
    "        if theta == None:\n",
    "            theta = self.trained\n",
    "        res, m = 0, X.shape[0]\n",
    "        for x, y  in zip(X, Y):\n",
    "            predicted = self.predict_proba(x, theta)\n",
    "            res += self.Cost(predicted, y)\n",
    "        return (-1/m)*res + self.MassiveRegularizationSummation(theta, m)\n",
    "    \n",
    "    def Cost(self, H, y):\n",
    "        return (1-y)*np.log(1-H)+y*np.log(H)\n",
    "    \n",
    "    def GradientDescent(self, X, y, m, theta):\n",
    "        derivative = self.TakeDerivatives(X, y, m, theta)\n",
    "        dev = float(\"inf\")\n",
    "        while self.norm(derivative, \"L2-norm\") > self.epsilon:\n",
    "            #theta = theta - self.learning_rate*derivative # Exclude Bias\n",
    "            for (i, value), deriv in zip(enumerate(theta), derivative):\n",
    "                theta[i] = theta[i]*(1-self.learning_rate*self.reg_lambda/m)-self.learning_rate*deriv\n",
    "            self.trained = theta\n",
    "            tmp = self.Loss(dev_x, dev_y, theta)\n",
    "            if tmp > dev:\n",
    "                print(\"Development error increased. Early stopping...\")\n",
    "                return theta\n",
    "            else:\n",
    "                dev = tmp\n",
    "                if self.count == 1:\n",
    "                    print(\"Dev: \" +str(dev))\n",
    "            derivative = self.TakeDerivatives(X, y, m, theta)\n",
    "        return theta\n",
    "    \n",
    "    def TakeDerivatives(self, X, y, m, theta):\n",
    "        delta, cost = \"None\", 0\n",
    "        for i in range(m):\n",
    "            a, z = self.FeedForward(X[i], theta)\n",
    "            cost += self.Cost(a[-1][0], y[i])\n",
    "            # Element-wise Addition: delta + result of BackPropagation\n",
    "            tmp = self.BackPropagation(a, z, y[i], theta)\n",
    "            if delta == \"None\":\n",
    "                delta = tmp\n",
    "            else:\n",
    "                for i, x in enumerate(tmp):\n",
    "                    delta[i] += x\n",
    "        for i, d in enumerate(delta):\n",
    "            delta[i] *= 1/m\n",
    "        self.verbal((-1/m)*cost+self.MassiveRegularizationSummation(theta, m))\n",
    "        return delta\n",
    "    \n",
    "    def FeedForward(self, X, theta):\n",
    "        a, z = list(), list()\n",
    "        a.append(X)\n",
    "        z.append(np.NaN)\n",
    "        for l in range(1, self.L):\n",
    "            z.append(theta[l-1].dot(a[-1]))\n",
    "            a.append(self.ActivationFunction(z[-1]))\n",
    "        return a, z\n",
    "    \n",
    "    def BackPropagation(self, a, z, y, theta):\n",
    "        delta, error = list(), list()\n",
    "        error.append(a[-1] - y)\n",
    "        for l in reversed(range(self.L-1)):\n",
    "            delta.append(error[-1].reshape(-1, 1).dot(a[l].reshape(1, -1)))\n",
    "            error.append(theta[l].T.dot(error[-1])*self.ActivationFunction(z[l], deriv=True))\n",
    "        return delta[::-1]\n",
    "\n",
    "    def verbal(self, x):\n",
    "        self.count %= self.interval\n",
    "        if self.count == 0:\n",
    "            print(x)\n",
    "        self.count += 1\n",
    "    \n",
    "    def norm(self, V, mode=\"L2-norm\"):\n",
    "        if mode==\"L2-norm\":\n",
    "            for i, v in enumerate(V):\n",
    "                V[i] = (v**2).sum()\n",
    "            res = np.sqrt((np.array(V)**2).sum())\n",
    "        if mode==\"L1-norm\":\n",
    "            for i, v in enumerate(V):\n",
    "                V[i] = np.abs(v).sum()\n",
    "            res = np.array(V).sum()\n",
    "        return res\n",
    "    \n",
    "    def ActivationFunction(self, X, deriv=False):\n",
    "        # Sigmoid Fucntion\n",
    "        value = 1/(1+math.e**-X)\n",
    "        if deriv:\n",
    "            #Return first derivative of function\n",
    "            return value*(1-value)\n",
    "        return value\n",
    "    def MassiveRegularizationSummation(self, theta, m):\n",
    "        res = 0 # Calculate the regularization term for cost funtion\n",
    "        for a in theta:\n",
    "            res += (a**2).sum()\n",
    "        return (self.reg_lambda/(2*m))*res\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 2 2 1]\n",
      "[ 0.71920559]\n",
      "Dev: [ 0.74437718]\n",
      "[ 0.71379255]\n",
      "Dev: [ 0.73498425]\n",
      "[ 0.70904448]\n",
      "Dev: [ 0.72659021]\n",
      "[ 0.70485755]\n",
      "Dev: [ 0.71905132]\n",
      "[ 0.70114714]\n",
      "Dev: [ 0.71224906]\n",
      "[ 0.69784385]\n",
      "Dev: [ 0.70608506]\n",
      "[ 0.69489034]\n",
      "Dev: [ 0.70047709]\n",
      "[ 0.69223895]\n",
      "Dev: [ 0.69535602]\n",
      "[ 0.68984983]\n",
      "Dev: [ 0.69066334]\n",
      "[ 0.68768943]\n",
      "Dev: [ 0.68634931]\n",
      "[ 0.6857294]\n",
      "Dev: [ 0.68237137]\n",
      "[ 0.68394563]\n",
      "Dev: [ 0.67869293]\n",
      "[ 0.68231752]\n",
      "Dev: [ 0.67528241]\n",
      "[ 0.68082739]\n",
      "Dev: [ 0.67211239]\n",
      "[ 0.67946]\n",
      "Dev: [ 0.66915901]\n",
      "[ 0.67820216]\n",
      "Dev: [ 0.66640135]\n",
      "[ 0.67704239]\n",
      "Dev: [ 0.66382109]\n",
      "[ 0.6759707]\n",
      "Dev: [ 0.66140205]\n",
      "[ 0.67497832]\n",
      "Dev: [ 0.65912993]\n",
      "[ 0.67405757]\n",
      "Dev: [ 0.65699204]\n",
      "[ 0.67320166]\n",
      "Dev: [ 0.65497708]\n",
      "[ 0.67240459]\n",
      "Dev: [ 0.65307497]\n",
      "[ 0.67166105]\n",
      "Dev: [ 0.65127668]\n",
      "[ 0.67096632]\n",
      "Dev: [ 0.6495741]\n",
      "[ 0.67031616]\n",
      "Dev: [ 0.64795993]\n",
      "[ 0.66970683]\n",
      "Dev: [ 0.64642758]\n",
      "[ 0.66913494]\n",
      "Dev: [ 0.6449711]\n",
      "[ 0.66859745]\n",
      "Dev: [ 0.64358509]\n",
      "[ 0.66809164]\n",
      "Dev: [ 0.64226464]\n",
      "[ 0.66761505]\n",
      "Dev: [ 0.64100529]\n",
      "[ 0.66716543]\n",
      "Dev: [ 0.63980295]\n",
      "[ 0.66674078]\n",
      "Dev: [ 0.63865389]\n",
      "[ 0.66633926]\n",
      "Dev: [ 0.63755472]\n",
      "[ 0.66595921]\n",
      "Dev: [ 0.6365023]\n",
      "[ 0.66559911]\n",
      "Dev: [ 0.63549374]\n",
      "[ 0.66525756]\n",
      "Dev: [ 0.63452641]\n",
      "[ 0.66493331]\n",
      "Dev: [ 0.63359786]\n",
      "[ 0.66462519]\n",
      "Dev: [ 0.63270584]\n",
      "[ 0.66433215]\n",
      "Dev: [ 0.63184827]\n",
      "[ 0.66405319]\n",
      "Dev: [ 0.6310232]\n",
      "[ 0.66378743]\n",
      "Dev: [ 0.63022886]\n",
      "[ 0.66353403]\n",
      "Dev: [ 0.62946357]\n",
      "[ 0.66329223]\n",
      "Dev: [ 0.6287258]\n",
      "[ 0.66306133]\n",
      "Dev: [ 0.62801411]\n",
      "[ 0.66284068]\n",
      "Dev: [ 0.62732715]\n",
      "[ 0.66262966]\n",
      "Dev: [ 0.62666367]\n",
      "[ 0.66242773]\n",
      "Dev: [ 0.62602251]\n",
      "[ 0.66223435]\n",
      "Dev: [ 0.62540257]\n",
      "[ 0.66204905]\n",
      "Dev: [ 0.62480282]\n",
      "[ 0.66187138]\n",
      "Dev: [ 0.62422232]\n",
      "[ 0.66170093]\n",
      "Dev: [ 0.62366015]\n",
      "[ 0.66153729]\n",
      "Dev: [ 0.62311547]\n",
      "[ 0.66138011]\n",
      "Dev: [ 0.62258749]\n",
      "[ 0.66122905]\n",
      "Dev: [ 0.62207546]\n",
      "[ 0.66108379]\n",
      "Dev: [ 0.62157868]\n",
      "[ 0.66094403]\n",
      "Dev: [ 0.62109649]\n",
      "[ 0.6608095]\n",
      "Dev: [ 0.62062825]\n",
      "[ 0.66067993]\n",
      "Dev: [ 0.62017339]\n",
      "[ 0.66055509]\n",
      "Dev: [ 0.61973133]\n",
      "[ 0.66043473]\n",
      "Dev: [ 0.61930156]\n",
      "[ 0.66031865]\n",
      "Dev: [ 0.61888357]\n",
      "[ 0.66020665]\n",
      "Dev: [ 0.6184769]\n",
      "[ 0.66009852]\n",
      "Dev: [ 0.61808109]\n",
      "[ 0.6599941]\n",
      "Dev: [ 0.61769573]\n",
      "[ 0.65989321]\n",
      "Dev: [ 0.6173204]\n",
      "[ 0.65979569]\n",
      "Dev: [ 0.61695473]\n",
      "[ 0.6597014]\n",
      "Dev: [ 0.61659835]\n",
      "[ 0.65961018]\n",
      "Dev: [ 0.61625092]\n",
      "[ 0.65952191]\n",
      "Dev: [ 0.6159121]\n",
      "[ 0.65943646]\n",
      "Dev: [ 0.6155816]\n",
      "[ 0.6593537]\n",
      "Dev: [ 0.6152591]\n",
      "[ 0.65927353]\n",
      "Dev: [ 0.61494432]\n",
      "[ 0.65919583]\n",
      "Dev: [ 0.614637]\n",
      "[ 0.6591205]\n",
      "Dev: [ 0.61433688]\n",
      "[ 0.65904745]\n",
      "Dev: [ 0.6140437]\n",
      "[ 0.65897658]\n",
      "Dev: [ 0.61375724]\n",
      "[ 0.65890781]\n",
      "Dev: [ 0.61347727]\n",
      "[ 0.65884105]\n",
      "Dev: [ 0.61320357]\n",
      "[ 0.65877623]\n",
      "Dev: [ 0.61293594]\n",
      "[ 0.65871326]\n",
      "Dev: [ 0.61267419]\n",
      "[ 0.65865208]\n",
      "Dev: [ 0.61241811]\n",
      "[ 0.65859262]\n",
      "Dev: [ 0.61216754]\n",
      "[ 0.65853481]\n",
      "Dev: [ 0.6119223]\n",
      "[ 0.65847859]\n",
      "Dev: [ 0.61168223]\n",
      "[ 0.65842391]\n",
      "Dev: [ 0.61144716]\n",
      "[ 0.6583707]\n",
      "Dev: [ 0.61121694]\n",
      "[ 0.65831892]\n",
      "Dev: [ 0.61099143]\n"
     ]
    }
   ],
   "source": [
    "NN = NeuralNetworkClassifier([2, 2], reg_lambda=0.1, learning_rate=0.001)\n",
    "NN.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sex, age, famsize, traveltime, studytime, activities, goout, famrel = 1, 17, 1, 1, 4, 0, 0, 5\n",
    "input_data = np.array([sex, age, famsize, traveltime, studytime, activities, goout, famrel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NN.predict_proba(input_data)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NN.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NN.score(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NN.trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
