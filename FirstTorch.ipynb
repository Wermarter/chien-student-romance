{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wermarter/anaconda3/lib/python3.5/site-packages/pandas/core/generic.py:4702: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "/home/wermarter/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2881: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/home/wermarter/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/wermarter/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/wermarter/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/wermarter/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/wermarter/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/wermarter/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>famsize</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>activities</th>\n",
       "      <th>goout</th>\n",
       "      <th>famrel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.473418</td>\n",
       "      <td>16.696203</td>\n",
       "      <td>0.711392</td>\n",
       "      <td>1.448101</td>\n",
       "      <td>2.035443</td>\n",
       "      <td>0.508861</td>\n",
       "      <td>3.108861</td>\n",
       "      <td>3.944304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499926</td>\n",
       "      <td>1.276043</td>\n",
       "      <td>0.453690</td>\n",
       "      <td>0.697505</td>\n",
       "      <td>0.839240</td>\n",
       "      <td>0.500555</td>\n",
       "      <td>1.113278</td>\n",
       "      <td>0.896659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sex         age     famsize  traveltime   studytime  activities  \\\n",
       "count  395.000000  395.000000  395.000000  395.000000  395.000000  395.000000   \n",
       "mean     0.473418   16.696203    0.711392    1.448101    2.035443    0.508861   \n",
       "std      0.499926    1.276043    0.453690    0.697505    0.839240    0.500555   \n",
       "min      0.000000   15.000000    0.000000    1.000000    1.000000    0.000000   \n",
       "25%      0.000000   16.000000    0.000000    1.000000    1.000000    0.000000   \n",
       "50%      0.000000   17.000000    1.000000    1.000000    2.000000    1.000000   \n",
       "75%      1.000000   18.000000    1.000000    2.000000    2.000000    1.000000   \n",
       "max      1.000000   22.000000    1.000000    4.000000    4.000000    1.000000   \n",
       "\n",
       "            goout      famrel  \n",
       "count  395.000000  395.000000  \n",
       "mean     3.108861    3.944304  \n",
       "std      1.113278    0.896659  \n",
       "min      1.000000    1.000000  \n",
       "25%      2.000000    4.000000  \n",
       "50%      3.000000    4.000000  \n",
       "75%      4.000000    5.000000  \n",
       "max      5.000000    5.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features Selection\n",
    "dataset = shuffle(pd.read_csv('student-mat.csv'))\n",
    "Y = dataset[['romantic']]\n",
    "X = dataset[['sex', 'age', 'famsize', 'traveltime', 'studytime', 'activities', 'goout', 'famrel']]\n",
    "Y['romantic'][Y['romantic']=='no'] = 0\n",
    "Y['romantic'][Y['romantic']=='yes'] = 1\n",
    "X['sex'][X['sex']=='F'] = 0\n",
    "X['sex'][X['sex']=='M'] = 1\n",
    "X['famsize'][X['famsize']=='LE3'] = 0\n",
    "X['famsize'][X['famsize']=='GT3'] = 1\n",
    "X['activities'][X['activities']=='no'] = 0\n",
    "X['activities'][X['activities']=='yes'] = 1\n",
    "X = X.apply(pd.to_numeric)\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(276, 39, 80)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Splitting into train set, validation set and test set\n",
    "def train_val_test_split(X, Y, dist):\n",
    "    X, Y = X.as_matrix().astype(float), Y.as_matrix().astype(float)\n",
    "    a, b, c = np.array(dist)\n",
    "    train_x, tmp_x, train_y, tmp_y = split(X, Y, test_size=(b+c)/(a+b+c))\n",
    "    val_x, test_x, val_y, test_y = split(tmp_x, tmp_y, test_size=c/(b+c))\n",
    "    return train_x, val_x, test_x, train_y, val_y, test_y\n",
    "train_x, val_x, test_x, train_y, val_y, test_y = train_val_test_split(X, Y, [7, 1, 2])\n",
    "len(train_x), len(val_x), len(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MLP_BinClassifier(nn.Module): # Multilayer perceptrons for binary classification\n",
    "    def __init__(self, \n",
    "                 layers=[8, 2, 2, 1], # Layers structure: number of units on each layer\n",
    "                 lr=0.01, # Learning rate\n",
    "                 reg_lambda=0.5, # Lambda value for regularization (weight decay)\n",
    "                 H_activ=F.tanh, # Hidden units' activation function\n",
    "                 L_activ=F.sigmoid, # Output units' activation function\n",
    "                ):\n",
    "        super(MLP_BinClassifier, self).__init__()\n",
    "        self.lr = lr\n",
    "        self.reg_lambda = reg_lambda\n",
    "        self.layers = layers\n",
    "        self.H_activ = H_activ\n",
    "        self.L_activ = L_activ\n",
    "        assert len(layers) >= 3\n",
    "        assert callable(H_activ) and callable(L_activ)\n",
    "        # Parameters generator: linears[0], linears[1],..., linears[L]\n",
    "        params = list()\n",
    "        for (idx, l) in enumerate(self.layers[:-1]):\n",
    "             params.append(nn.Linear(l, self.layers[idx+1]))\n",
    "        self.linears = nn.ModuleList(params)\n",
    "    def forward(self, X):\n",
    "        X = X.view(1, -1)\n",
    "        for i in range(len(self.linears)-1):\n",
    "            linear = self.linears[i]\n",
    "            X = self.H_activ(linear(X))\n",
    "        linear = self.linears[-1]\n",
    "        X = self.L_activ(linear(X))\n",
    "        return X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = MLP_BinClassifier([8, 1, 1, 1, 1, 1], reg_lambda=0)\n",
    "cuda = torch.cuda.is_available()\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=model.lr, weight_decay=model.reg_lambda)\n",
    "def per_example_loss(output, target):\n",
    "    return -((1-target)*(1-output).log() + target*(output).log()) # negative log likelihood\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = per_example_loss\n",
    "def evaluate(X, y):\n",
    "    model.eval()\n",
    "    losses = list()\n",
    "    correct = 0\n",
    "    for (data, target) in zip(X, y):\n",
    "        data, target = torch.Tensor(data), torch.Tensor(target)\n",
    "        if cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data, volatile=True), Variable(target, volatile=True)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        losses.append(loss.data[0])\n",
    "        output, target = 1 if output.data[0] > 0.5 else 0, target.data[0]\n",
    "        correct += 1 if (output==target) else 0\n",
    "    return (sum(losses)/len(losses)), correct/len(losses)\n",
    "def train():\n",
    "    model.train()\n",
    "    losses = list()\n",
    "    for (data, target) in zip(train_x, train_y):\n",
    "        data, target = torch.Tensor(data), torch.Tensor(target)\n",
    "        if cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        output = model(data)\n",
    "        optimizer.zero_grad() # Empty the gradients\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward() # Take the Gradients\n",
    "        optimizer.step() # Update the model\n",
    "        losses.append(loss.data[0])\n",
    "    return sum(losses)/len(losses), evaluate(val_x, val_y)[0] # returns Loss and Cross-Validation Error\n",
    "def test():\n",
    "    return evaluate(test_x, test_y) # returns Loss and Accuracy\n",
    "def predict(X):\n",
    "    return model(Variable(torch.Tensor(X).cuda())).data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wermarter/anaconda3/lib/python3.5/site-packages/torch/serialization.py:147: UserWarning: Couldn't retrieve source code for container of type MLP_BinClassifier. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "Training Loss: 0.6570440369887628\n",
      "CrossValidation Error: 0.6379277201799246\n",
      "Test Loss: 0.6839456751942634\n",
      "Accuracy: 0.5875\n",
      "=======================================\n",
      "Epoch:  2\n",
      "Training Loss: 0.6248289449275404\n",
      "CrossValidation Error: 0.6372621273383116\n",
      "Test Loss: 0.6857256881892682\n",
      "Accuracy: 0.5875\n",
      "=======================================\n",
      "Epoch:  3\n",
      "Training Loss: 0.6244365163687347\n",
      "CrossValidation Error: 0.6372076143056918\n",
      "Test Loss: 0.6859062511473895\n",
      "Accuracy: 0.5875\n",
      "=======================================\n",
      "Epoch:  4\n",
      "Training Loss: 0.6243813960016638\n",
      "CrossValidation Error: 0.6371690974785731\n",
      "Test Loss: 0.6860340937972069\n",
      "Accuracy: 0.5875\n",
      "=======================================\n",
      "Epoch:  5\n",
      "Training Loss: 0.6243401007807773\n",
      "CrossValidation Error: 0.637136330207189\n",
      "Test Loss: 0.6861488737165928\n",
      "Accuracy: 0.5875\n",
      "=======================================\n",
      "Epoch:  6\n",
      "Training Loss: 0.6243042342256808\n",
      "CrossValidation Error: 0.6371082212680426\n",
      "Test Loss: 0.6862511180341244\n",
      "Accuracy: 0.5875\n",
      "=======================================\n",
      "Epoch:  7\n",
      "Training Loss: 0.6242729964247649\n",
      "CrossValidation Error: 0.6370842143511161\n",
      "Test Loss: 0.6863411221653223\n",
      "Accuracy: 0.5875\n",
      "=======================================\n",
      "Epoch:  8\n",
      "Training Loss: 0.6242458338754765\n",
      "CrossValidation Error: 0.6370636438712095\n",
      "Test Loss: 0.6864202655851841\n",
      "Accuracy: 0.5875\n",
      "=======================================\n",
      "Epoch:  9\n",
      "Training Loss: 0.6242221194332924\n",
      "CrossValidation Error: 0.6370459382350628\n",
      "Test Loss: 0.6864898908883333\n",
      "Accuracy: 0.5875\n",
      "=======================================\n",
      "Epoch:  10\n",
      "Training Loss: 0.6242013170883276\n",
      "CrossValidation Error: 0.637030636652922\n",
      "Test Loss: 0.6865512248128652\n",
      "Accuracy: 0.5875\n",
      "=======================================\n",
      "Epoch:  20\n",
      "Training Loss: 0.6240825402563897\n",
      "CrossValidation Error: 0.6369387041299771\n",
      "Test Loss: 0.6869360588490963\n",
      "Accuracy: 0.5875\n",
      "=======================================\n",
      "Epoch:  30\n",
      "Training Loss: 0.6240330817906753\n",
      "CrossValidation Error: 0.6369243073157775\n",
      "Test Loss: 0.6870233673602343\n",
      "Accuracy: 0.5875\n",
      "=======================================\n",
      "Epoch:  40\n",
      "Training Loss: 0.6240110324992649\n",
      "CrossValidation Error: 0.6368886904838758\n",
      "Test Loss: 0.6871357843279838\n",
      "Accuracy: 0.5875\n",
      "=======================================\n",
      "Epoch:  50\n",
      "Training Loss: 0.6240002935131391\n",
      "CrossValidation Error: 0.6368844761298253\n",
      "Test Loss: 0.6872034136205911\n",
      "Accuracy: 0.5875\n",
      "=======================================\n",
      "Epoch:  60\n",
      "Training Loss: 0.6239951896494713\n",
      "CrossValidation Error: 0.6368796405119773\n",
      "Test Loss: 0.6872237917035818\n",
      "Accuracy: 0.5875\n",
      "=======================================\n",
      "Epoch:  70\n",
      "Training Loss: 0.6239919546937597\n",
      "CrossValidation Error: 0.6368787747163039\n",
      "Test Loss: 0.6872324999421835\n",
      "Accuracy: 0.5875\n",
      "=======================================\n",
      "Epoch:  80\n",
      "Training Loss: 0.6239909437903459\n",
      "CrossValidation Error: 0.636877369422179\n",
      "Test Loss: 0.6872366227209568\n",
      "Accuracy: 0.5875\n",
      "=======================================\n",
      "Epoch:  90\n",
      "Training Loss: 0.6239798673685046\n",
      "CrossValidation Error: 0.6368912955125173\n",
      "Test Loss: 0.6871949337422848\n",
      "Accuracy: 0.5875\n",
      "=======================================\n",
      "Early stopping on epoch: 99\n",
      "Restoring best model from epoch: 93\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "log_interval = 10\n",
    "allow_early_stop = True\n",
    "pre_cv_error = float('inf')\n",
    "patience = 5 # Number of steps with increasing cross-validation error to tolerate before early stopping\n",
    "tolerated = False\n",
    "for epoch in range(1, n_epochs+1): # Main loop\n",
    "    loss, cv_error = train()\n",
    "    loss_test, accuracy = test()\n",
    "    if cv_error > pre_cv_error:\n",
    "        if allow_early_stop:\n",
    "            if patience == 0:\n",
    "                print('Early stopping on epoch:', epoch)\n",
    "                print('Restoring best model from epoch:', best_idx)\n",
    "                model = torch.load('best_model.pkl')\n",
    "                break\n",
    "            else:\n",
    "                patience -= 1\n",
    "                tolerated = True\n",
    "    else:\n",
    "        patience = 5\n",
    "        best_idx = epoch\n",
    "        torch.save(model, 'best_model.pkl') # Can be time-consuming if model is large\n",
    "    if not tolerated:\n",
    "        pre_cv_error = cv_error\n",
    "    # Logging\n",
    "    if (epoch % log_interval == 0)or(epoch<10):\n",
    "        print(\"Epoch: \", epoch)\n",
    "        print(\"Training Loss: {}\\nCrossValidation Error: {}\\nTest Loss: {}\\nAccuracy: {}\"\n",
    "              .format(loss, cv_error, loss_test, accuracy))\n",
    "        print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sex - 0:female or 1:male\n",
    "# age - ideal range is from 15 to 22\n",
    "# famsize - family size (0 ~ <=3 or 1 ~ >3)\n",
    "# traveltime - home to school travel time (1 ~ <15 min, 2 ~ 15-30 min, 3 ~ 30 min - 1 hour, or 4 ~ >1 hour)\n",
    "# studytime - weekly study time (1 ~ <2 hours, 2 ~ 2-5 hours, 3 ~ 5-10 hours, or 4 ~ >10 hours)\n",
    "# activities - extra-curricular activities (1 ~ yes or 0 ~ no)\n",
    "# goout - going out with friends (from 1 ~ very low to 5 ~ very high)\n",
    "# famrel - quality of family relationships (from 1 ~ very bad to 5 ~ excellent)\n",
    "sex, age, famsize, traveltime, studytime, activities, goout, famrel = 0, 23, 1, 2, 4, 1, 3, 4\n",
    "input_data = np.array([sex, age, famsize, traveltime, studytime, activities, goout, famrel]).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.639376401901245"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(input_data)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3463935852050781"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(train_x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
